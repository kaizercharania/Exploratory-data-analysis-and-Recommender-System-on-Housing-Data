{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Educational Purpose Only!\n",
    "## Century21 Webscraping https://century21.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "\n",
    "data = []\n",
    "myfile = open(\"/Users/kaizer/Desktop/cities.txt\",encoding='utf-8')\n",
    "data1 = myfile.read()\n",
    "myfile.close()\n",
    "data1 = list(data1.splitlines())\n",
    "search_list = []\n",
    "s=1\n",
    "for i in range(len(data1)):\n",
    "    string_name = data1[i]+\"-ca/LCCA\" \n",
    "    string_name = string_name.replace(\" \",\"-\")\n",
    "    string_name = string_name + data1[i].upper().replace(\" \",\"\")\n",
    "    search_list.append(string_name)\n",
    "print (search_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in (range(len(search_list))):\n",
    "    page_requests =  requests.get(\"https://www.century21.com/real-estate/\" + str(search_list[i]) )\n",
    "    page_content = page_requests.content\n",
    "    page_soup = BeautifulSoup(page_content,\"html.parser\")\n",
    "    if page_soup.find('a',{\"class\":\"bug\"}) != None:\n",
    "        num_results = int(page_soup.find('a',{\"class\":\"bug\"}).text)\n",
    "        num_pages = int(num_results/20) + (num_results % 20 > 0)\n",
    "        url = (\"https://www.century21.com/real-estate/\" + str(search_list[i]))\n",
    "        print(\"url: \" + url)\n",
    "        print(\"number of pages: {}\".format(num_pages))\n",
    "        print(\"number of results: {}\".format(num_results))\n",
    "        \n",
    "        for i in range(num_pages):\n",
    "            print (\"total_entries: {}\".format(s))\n",
    "            html_req = requests.get(url)\n",
    "            html_content = html_req.content\n",
    "            html_soup = BeautifulSoup(html_content,\"html.parser\")\n",
    "            regex = re.compile('.*infinite-item property-card clearfix property-card*')\n",
    "            data_all = html_soup.find_all(\"div\",{\"class\":regex})\n",
    "            for items in range(len(data_all)):\n",
    "                if  data_all[items].find('a',{\"class\":\"listing-price\"}) != None:\n",
    "                    price = data_all[items].find('a',{\"class\":\"listing-price\"}).text.replace(\"\\n\",\"\").replace(\" \",\"\")\n",
    "\n",
    "                if  data_all[items].find('div',{\"class\":\"property-beds\"}) != None:\n",
    "                    beds = data_all[items].find('div',{\"class\":\"property-beds\"}).text.replace(\"\\n\",\"\").replace(\" \",\"\").replace(\"beds\",\"\").replace(\"bed\",\"\")\n",
    "\n",
    "                if  data_all[items].find('div',{\"class\":\"property-baths\"}) != None:\n",
    "                    baths = data_all[items].find('div',{\"class\":\"property-baths\"}).text.replace(\"\\n\",\"\").replace(\" \",\"\").replace(\"baths\",\"\").replace(\"bath\",\"\")\n",
    "                if  data_all[items].find('div',{\"class\":\"property-sqft\"}) != None:\n",
    "                    area = data_all[items].find('div',{\"class\":\"property-sqft\"}).text.replace(\"\\n\",\"\").replace(\" \",\"\").replace(\"sq.ft\",\"\")\n",
    "                if  data_all[items].find('div',{\"class\":\"property-address\"}) != None:\n",
    "                    street = data_all[items].find('div',{\"class\":\"property-address\"}).text.replace(\"\\n\",\"\").replace(\"   \",\"\")\n",
    "                if  data_all[items].find('div',{\"class\":\"property-city\"}) !=None:\n",
    "                    city_state_pin = data_all[items].find('div',{\"class\":\"property-city\"}).text.replace(\"\\n\",\"\").replace(\"   \",\"\").split(\" \")\n",
    "                    if len(city_state_pin) >=5:\n",
    "                        city = city_state_pin[0] + \" \" + city_state_pin[1]+ \" \" + city_state_pin[2]\n",
    "                        state = city_state_pin[3]\n",
    "                        pin = city_state_pin[4]\n",
    "                    elif len(city_state_pin) ==4 :\n",
    "                        city = city_state_pin[0] + \" \" + city_state_pin[1]\n",
    "                        state = city_state_pin[2]\n",
    "                        pin = city_state_pin[3]\n",
    "                    elif len(city_state_pin) <4:\n",
    "                        city = city_state_pin[0] \n",
    "                        state = city_state_pin[1]\n",
    "                        pin = city_state_pin[2]\n",
    "                d = {\"an0\": s ,\"area\":area,\"beds\":beds,\"baths\":baths,\"street\":street,\"city\":city,\"state\":state,\"pin\":pin,\"price\": price}\n",
    "                s +=1\n",
    "                data.append(d)\n",
    "            print(s)\n",
    "            if html_soup.find('link',{\"rel\":\"next\"}) != None:\n",
    "                url = html_soup.find('link',{\"rel\":\"next\"}, href=True)['href']\n",
    "df = pandas.DataFrame(data)\n",
    "df.to_csv(\"scraped_century21_data.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
